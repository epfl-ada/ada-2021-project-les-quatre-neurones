{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import json\n",
    "import requests\n",
    "import findspark\n",
    "findspark.init('/Users/tatianacogne/spark')\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sf\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import urllib.request as r\n",
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "from urllib.request import urlopen, Request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark context\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 \n",
    "df = spark.read.json('data/quotes-2020.json.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process df with pypsark\n",
    "Note: not able to put it back in a JSON file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select([c for c in df.columns if c in ['date','qids','quotation','quoteID']]).filter(sf.size('qids') > 0)\n",
    "rdd2=df.rdd.map(lambda x: (datetime.strptime(x['date'], '%Y-%m-%d %H:%M:%S'),x['quoteID'][11:],x['quotation'],x['qids']))  \n",
    "df2=rdd2.toDF(['date','quoteID','quotation','qids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'data/quotes-2020.json.bz2' \n",
    "path_to_out = 'data/sp_qids_quotes-2020-process.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            #instance['date'] = datetime.strptime(instance['date'], '%Y-%m-%d %H:%M:%S') \n",
    "            instance['quoteID']= instance['quoteID'][11:]\n",
    "            if(len(instance['qids'])!=0):\n",
    "                instance['qids'] = instance['qids'][0]\n",
    "                instance = dict((key,value) for key, value in instance.items() if key in('date','quoteID','quotation','qids'))\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'data/quotes-2019.json.bz2' \n",
    "path_to_out = 'data/quotes-2019-process.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            #instance['date'] = datetime.strptime(instance['date'], '%Y-%m-%d %H:%M:%S') \n",
    "            instance['quoteID']= instance['quoteID'][11:]\n",
    "            if(len(instance['qids'])!=0):\n",
    "                instance['qids'] = instance['qids'][0]\n",
    "                instance = dict((key,value) for key, value in instance.items() if key in('date','quoteID','quotation','qids'))\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'data/quotes-2018.json.bz2' \n",
    "path_to_out = 'data/quotes-2018-process.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            #instance['date'] = datetime.strptime(instance['date'], '%Y-%m-%d %H:%M:%S') \n",
    "            instance['quoteID']= instance['quoteID'][11:]\n",
    "            if(len(instance['qids'])!=0):\n",
    "                instance['qids'] = instance['qids'][0]\n",
    "                instance = dict((key,value) for key, value in instance.items() if key in('date','quoteID','quotation','qids'))\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'data/quotes-2017.json.bz2' \n",
    "path_to_out = 'data/quotes-2017-process.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            #instance['date'] = datetime.strptime(instance['date'], '%Y-%m-%d %H:%M:%S') \n",
    "            instance['quoteID']= instance['quoteID'][11:]\n",
    "            if(len(instance['qids'])!=0):\n",
    "                instance['qids'] = instance['qids'][0]\n",
    "                instance = dict((key,value) for key, value in instance.items() if key in('date','quoteID','quotation','qids'))\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'data/quotes-2016.json.bz2' \n",
    "path_to_out = 'data/quotes-2016-process.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            #instance['date'] = datetime.strptime(instance['date'], '%Y-%m-%d %H:%M:%S') \n",
    "            instance['quoteID']= instance['quoteID'][11:]\n",
    "            if(len(instance['qids'])!=0):\n",
    "                instance['qids'] = instance['qids'][0]\n",
    "                instance = dict((key,value) for key, value in instance.items() if key in('date','quoteID','quotation','qids'))\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'data/quotes-2015.json.bz2' \n",
    "path_to_out = 'data/quotes-2015-process.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            #instance['date'] = datetime.strptime(instance['date'], '%Y-%m-%d %H:%M:%S') \n",
    "            instance['quoteID']= instance['quoteID'][11:]\n",
    "            if(len(instance['qids'])!=0):\n",
    "                instance['qids'] = instance['qids'][0]\n",
    "                instance = dict((key,value) for key, value in instance.items() if key in('date','quoteID','quotation','qids'))\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp = pd.read_parquet('data/speaker_attributes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp = df_sp[['id','label','nationality','occupation','ethnic_group', 'party','religion']].copy()\n",
    "df_sp = df_sp.rename(columns={\"nationality\": \"nationality_qids\", \"ethnic_group\": \"ethnic_qids\",\"occupation\":\"occupation_qids\",\"party\":'party_qids','id':'speaker_qids','label':'speaker_label','religion':'religion_qids'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QIDS of all different nationalities, occupations, ethnic, party, religion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationality_qids = df_sp['nationality_qids'].explode('nationality_qids').drop_duplicates().values\n",
    "occupation_qids = df_sp['occupation_qids'].explode('occupation_qids').drop_duplicates().values\n",
    "ethnic_qids = df_sp['ethnic_qids'].explode('ethnic_qids').drop_duplicates().values\n",
    "party_qids = df_sp['party_qids'].explode('party_qids').drop_duplicates().values\n",
    "religion_qids = df_sp['religion_qids'].explode('religion_qids').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label(qids):\n",
    "    url = 'https://www.wikidata.org/wiki/'\n",
    "    url_qids = url+qids\n",
    "    ru =r.Request(url_qids,headers={'Connection': 'close'})\n",
    "    page = urlopen(ru).read()\n",
    "    soup = BeautifulSoup(page)\n",
    "    label = soup.find(\"span\", {\"class\":\"wikibase-title-label\"}).text\n",
    "    return label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Religion QIDS - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_qids = [x for x in religion_qids if x!=None]\n",
    "df_religion = pd.DataFrame()\n",
    "df_religion['qids'] = religion_qids\n",
    "df_religion['label'] = df_religion['qids'].apply(lambda x : find_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_religion.to_json('data/religion.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nationality QIDS - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationality_qids = [x for x in nationality_qids if x!=None]\n",
    "df_nationality = pd.DataFrame()\n",
    "df_nationality['qids'] = nationality_qids\n",
    "df_nationality['label'] = df_nationality['qids'].apply(lambda x : find_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nationality.to_json('data/nationality.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnic QIDS - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnic_qids = [x for x in ethnic_qids if x!=None]\n",
    "df_ethnic = pd.DataFrame()\n",
    "df_ethnic['ethnic_qids'] = ethnic_qids\n",
    "df_ethnic['ethnic_label'] = df_ethnic['ethnic_qids'].apply(lambda x : find_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ethnic.to_json('data/ethnic.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Party QIDS - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_qids = [x for x in party_qids if x!=None]\n",
    "df_party = pd.DataFrame()\n",
    "df_party['party_qids'] = party_qids\n",
    "df_party['party_label'] = df_party['party_qids'].apply(lambda x : find_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_party.to_json('data/party.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation QIDS - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_qids = [x for x in occupation_qids if x!=None]\n",
    "df_occupation = pd.DataFrame()\n",
    "df_occupation['occupation_qids'] = occupation_qids\n",
    "df_occupation['occupation_label'] = df_occupation['occupation_qids'].apply(lambda x : find_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occupation.to_json('data/occupation.json')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
