{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "quote_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlrcSV_08FnP"
      },
      "source": [
        "# Pipeline Description\n",
        "\n",
        "In this notebook, the relevant quotes for our data story are fetched and stored as new files. We use pyspark to treat large dataframes and convert them to  pandas dataframes if you want to modify them in this notebook.\n",
        "\n",
        "WARNING : this notebook is made to be run on google colab. Please modify the paths referenced in the following cells to match your own setup , whether on Colab or on your machine.
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmVGx73D8lk8",
        "outputId": "1e860b09-83e0-4aa2-c28d-619fe9a45200"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd \"/content/drive/My Drive/ADA/Project/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/ADA/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4iM2AndPx-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2832f58-152a-4ff4-d3c5-937a019cd859"
      },
      "source": [
        "!pip install pyspark\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import bz2\n",
        "import json\n",
        "import requests\n",
        "from pyspark.sql import functions as f"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "fUpeNyBhco00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-WdSDZJ8FnY"
      },
      "source": [
        "def fetch_quotes(pyspark_dataframe, year, keyword_list, filename):\n",
        "  ''' Inputs : * pyspark_dataframe (Object, contains the data)\n",
        "               * year (int)\n",
        "               * keyword_list (list of strings)\n",
        "               * filename (name attributed when saving the result)\n",
        "      Outputs : pandas_dfquotes (Pandas dataframe)\n",
        "      \n",
        "  This function takes a 'year' to fetch the right file in memory, and a list of keywords which will determine what quotes to select in the 'pyspark_dataframe'.\n",
        "  The selected quotes will be saved in a file named 'filename', with format json. I converts the quotes to a Pandas dataframe and returns them'''\n",
        "\n",
        "  print('loading...')\n",
        "  pyspark_dfquotes = pyspark_dataframe\n",
        "\n",
        "  print('reading keywords...')\n",
        "  # transform the keywords to a dataframe\n",
        "  df_keywords = spark.createDataFrame(keyword_list, 'string').toDF('keywords')\n",
        "\n",
        "\n",
        "  print('filtering the quotes...')\n",
        "  #fetch the corresponding quotes \n",
        "  joined = pyspark_dfquotes.join(df_keywords, f.col('quotation').contains(f.col('keywords')), 'left').withColumn('isRT', f.expr('if(keywords is null, False, True)')).drop('keywords')\n",
        "  pyspark_dfquotes = joined.filter(joined.isRT == 'true')\n",
        "\n",
        "  print('converting to pandas dataframe...')\n",
        "  # to pandas the dataframe, which is then returned for additional purposes\n",
        "  pandas_dfquotes = pyspark_dfquotes.toPandas()\n",
        "  pandas_dfquotes = pandas_dfquotes.drop('isRT', axis = 1)\n",
        "\n",
        "\n",
        "  print('write to compressed json file')\n",
        "  # saved the dataframe to a json file\n",
        "  filename = 'data/'+ filename\n",
        "  pandas_dfquotes.to_json(path_or_buf=filename) #if you want a compression, you can add the type directly in the filename among these : {‘infer’, ‘gzip’, ‘bz2’, ‘zip’, ‘xz’, None}\n",
        "\n",
        "  return pandas_dfquotes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2015"
      ],
      "metadata": {
        "id": "OANPeUeEGGm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = 2015\n",
        "# Load the dataframe corresponding to the year\n",
        "path = pathlib.Path('quote_extraction.ipynb').parent.resolve()\n",
        "path = str(path)\n",
        "path_to_file = path + '/data/quotes-' + str(year) + '-process.json.bz2' \n",
        "pyspark_dfquotes_2015 = spark.read.json(path_to_file)"
      ],
      "metadata": {
        "id": "R63Gd5dnGKP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tesla\n",
        "keywords_2015_Tesla = ['Tesla', 'tesla', 'Model S ', 'model S ', 'model s ', 'Model S,', 'model S,', 'model s,', 'Model X', 'model X', 'model x', 'Model Y', 'model Y', 'model y']\n",
        "pandas_Tesla_2015 = fetch_quotes (pyspark_dfquotes_2015, year = 2015, keyword_list = keywords_2015_Tesla , filename = 'Tesla-quotes-2015.json') # 2405 quotes"
      ],
      "metadata": {
        "id": "oMm8zM1LGsLR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05098fca-80ac-4bdd-b9fc-c9c5cf483d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chevrolet\n",
        "keywords_2015_Chevy = ['Chevrolet', 'chevrolet', 'Silverado', 'silverado']\n",
        "pandas_Chevy_2015 = fetch_quotes (pyspark_dfquotes_2015, year = 2015, keyword_list = keywords_2015_Chevy , filename = 'Chevy-quotes-2015.json') # 918 quotes"
      ],
      "metadata": {
        "id": "I7XsM17fIhf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df73216e-4feb-4ea0-f405-e21f43487ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toyota\n",
        "keywords_2015_Toyota = ['Toyota', 'toyota']\n",
        "pandas_Toyota_2015 = fetch_quotes (pyspark_dfquotes_2015, year = 2015, keyword_list = keywords_2015_Toyota , filename = 'Toyota-quotes-2015.json') # 918 quotes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUIMgWqPThQG",
        "outputId": "74ad3182-950c-43a5-976b-5f4b3c44c9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2016"
      ],
      "metadata": {
        "id": "1HvljtmKGPo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = 2016\n",
        "# Load the dataframe corresponding to the year\n",
        "path_to_file = path + '/data/quotes-' + str(year) + '-process.json.bz2' \n",
        "pyspark_dfquotes_2016 = spark.read.json(path_to_file)"
      ],
      "metadata": {
        "id": "t_BE4NSkGcLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tesla\n",
        "keywords_2016_Tesla = ['Tesla', 'tesla', 'Model S ', 'model S ', 'model s ', 'Model S,', 'model S,', 'model s,','Model X', 'model X', 'model x', 'Model Y', 'model Y', 'model y', 'Model 3', 'model 3', 'model three']\n",
        "pandas_Tesla_2016 = fetch_quotes (pyspark_dfquotes_2016 , year = 2016, keyword_list = keywords_2016_Tesla , filename = 'Tesla-quotes-2016.json')  # 2199 quotes"
      ],
      "metadata": {
        "id": "l5Qy-76nGqU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eca7e54-b6ec-45f2-dcc6-0b1b18409e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chevrolet\n",
        "keywords_2016_Chevy = ['Chevrolet', 'chevrolet', 'Silverado', 'silverado']\n",
        "pandas_Chevy_2016 = fetch_quotes (pyspark_dfquotes_2016, year = 2016, keyword_list = keywords_2016_Chevy , filename = 'Chevy-quotes-2016.json')# 577 quotes"
      ],
      "metadata": {
        "id": "kGkmYz5nJcRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c556e5-80ad-4202-98cc-0d2497f19e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toyota\n",
        "keywords_2016_Toyota = ['Toyota', 'toyota']\n",
        "pandas_Toyota_2016 = fetch_quotes (pyspark_dfquotes_2016 , year = 2016, keyword_list = keywords_2016_Toyota , filename = 'Toyota-quotes-2016.json') # "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFiP8IbRUqEw",
        "outputId": "ceb94a7e-2637-4c73-d7aa-8f2b65d71e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2017"
      ],
      "metadata": {
        "id": "PLZDPNPDGSeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  year = 2017\n",
        "  # Load the dataframe corresponding to the year\n",
        "  path_to_file = path + '/data/quotes-' + str(year) + '-process.json.bz2' \n",
        "  pyspark_dfquotes_2017 = spark.read.json(path_to_file)"
      ],
      "metadata": {
        "id": "Aun8-UGgGdHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tesla\n",
        "keywords_2017_Tesla = ['Tesla', 'tesla', 'Model S ', 'model S ', 'model s','Model S,', 'model S,', 'model s,', 'Model X', 'model X', 'model x', 'Model Y', 'model Y', 'model y', 'Model 3', 'model 3', 'model three', 'Tesla Roadster', 'Tesla roadster', 'tesla roadster', 'Tesla Cybertruck', 'tesla Cybertruck', 'tesla cybertruck','Cybertruck', 'cybertruck']\n",
        "pandas_Tesla_2017 = fetch_quotes (pyspark_dfquotes_2017, year = 2017, keyword_list = keywords_2017_Tesla , filename = 'Tesla-quotes-2017.json') # 4204 quotes"
      ],
      "metadata": {
        "id": "CxZU0NiZJlK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56a8b5f-992b-4228-9874-3d90e637028a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chevrolet\n",
        "keywords_2017_Chevy = ['Chevrolet', 'chevrolet', 'Silverado', 'silverado']\n",
        "pandas_Chevy_2017 = fetch_quotes (pyspark_dfquotes_2017, year = 2017, keyword_list = keywords_2017_Chevy , filename = 'Chevy-quotes-2017.json')  # 906 quotes"
      ],
      "metadata": {
        "id": "QZ11YJyIJlln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f059a17-a6e9-4191-e81f-7a8cb72c61e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toyota\n",
        "keywords_2017_Toyota = ['Toyota', 'toyota']\n",
        "pandas_Toyota_2017 = fetch_quotes (pyspark_dfquotes_2017 , year = 2017, keyword_list = keywords_2017_Toyota , filename = 'Toyota-quotes-2017.json') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnyp-29fU70f",
        "outputId": "2a8278ba-4c91-49b2-c143-e3768cbdfd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2018"
      ],
      "metadata": {
        "id": "N4OlfFATGT-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = 2018\n",
        "# Load the dataframe corresponding to the year\n",
        "path = pathlib.Path('quote_extraction.ipynb').parent.resolve()\n",
        "path = str(path)\n",
        "path_to_file = path + '/data/quotes-' + str(year) + '-process.json.bz2' \n",
        "pyspark_dfquotes_2018 = spark.read.json(path_to_file)"
      ],
      "metadata": {
        "id": "HfmihUH-GdsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tesla\n",
        "keywords_2018_Tesla = ['Tesla', 'tesla', 'Model S ', 'model S ', 'model s ','Model S,', 'model S,', 'model s,', 'Model X', 'model X', 'model x', 'Model Y', 'model Y', 'model y', 'Model 3', 'model 3', 'model three', 'Tesla Roadster', 'Tesla roadster', 'tesla roadster', 'Tesla Cybertruck', 'tesla Cybertruck', 'tesla cybertruck','Cybertruck', 'cybertruck']\n",
        "pandas_Tesla_2018 = fetch_quotes (pyspark_dfquotes_2018, year = 2018, keyword_list = keywords_2018_Tesla , filename = 'Tesla-quotes-2018.json') # 5663 quotes"
      ],
      "metadata": {
        "id": "9P0eQOOEJt_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a791fd9-42d6-4e94-9668-fece28732113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chevrolet\n",
        "keywords_2016_Chevy = ['Chevrolet', 'chevrolet', 'Silverado', 'silverado']\n",
        "pandas_Chevy_2018 = fetch_quotes (pyspark_dfquotes_2018, year = 2018, keyword_list = keywords_2016_Chevy , filename = 'Chevy-quotes-2018.json')  # 850 quotes"
      ],
      "metadata": {
        "id": "8fmzz8ZjJumh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7684a21-90f7-4075-ee15-d9a9c0b410f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toyota\n",
        "keywords_2018_Toyota = ['Toyota', 'toyota']\n",
        "pandas_Toyota_2018 = fetch_quotes (pyspark_dfquotes_2018 , year = 2018, keyword_list = keywords_2018_Toyota , filename = 'Toyota-quotes-2018.json') # "
      ],
      "metadata": {
        "id": "lVaAeTemVXrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2019"
      ],
      "metadata": {
        "id": "mDW2de88GXeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = 2019\n",
        "# Load the dataframe corresponding to the year\n",
        "path_to_file = path + '/data/quotes-' + str(year) + '-process.json.bz2' \n",
        "pyspark_dfquotes_2019 = spark.read.json(path_to_file)"
      ],
      "metadata": {
        "id": "QGAAYwL6GeW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tesla 2019 \n",
        "keywords_2019_Tesla = ['Tesla', 'tesla', 'Model S ', 'model S ', 'model s', 'Model S,', 'model S,', 'model s,','Model X', 'model X', 'model x', 'Model Y', 'model Y', 'model y', 'Model 3', 'model 3', 'model three', 'Tesla Roadster', 'Tesla roadster', 'tesla roadster', 'Tesla Cybertruck', 'tesla Cybertruck', 'tesla cybertruck', 'Cybertruck', 'cybertruck']\n",
        "pandas_Tesla_2019 = fetch_quotes (pyspark_dfquotes_2019, year = 2019, keyword_list = keywords_2019_Tesla , filename = 'Tesla-quotes-2019.json') # 4167 quotes"
      ],
      "metadata": {
        "id": "gxrG-Qww3wXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c51ada-d940-4e24-a667-4ae67ff66149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chevrolet 2019 \n",
        "keywords_2019_Chevy = ['Chevrolet', 'Silverado', 'Chevrolet Silverado']\n",
        "pandas_Chevy_2019 = fetch_quotes (pyspark_dfquotes_2019, year = 2019, keyword_list = keywords_2019_Chevy , filename = 'Chevy-quotes-2019.json') # 701  quotes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0_9czD73wxl",
        "outputId": "6f5b08c0-7b5c-4cda-ff2b-29ae61ce3e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toyota\n",
        "keywords_2019_Toyota = ['Toyota', 'toyota']\n",
        "pandas_Toyota_2019 = fetch_quotes (pyspark_dfquotes_2019 , year = 2019, keyword_list = keywords_2019_Toyota , filename = 'Toyota-quotes-2019.json') # "
      ],
      "metadata": {
        "id": "5Wh5a3ieVdPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2020"
      ],
      "metadata": {
        "id": "VZqmRTS0MEUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = 2020\n",
        "# Load the dataframe corresponding to the year\n",
        "path_to_file = path + '/data/quotes-' + str(year) + '-process.json.bz2' \n",
        "pyspark_dfquotes_2020 = spark.read.json(path_to_file)"
      ],
      "metadata": {
        "id": "L6o6OiywMDTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tesla 2020\n",
        "keywords_2020_Tesla =  ['Tesla', 'tesla', 'Model S ', 'model S ', 'model s ', 'Model S,', 'model S,', 'model s,', 'Model X', 'model X', 'model x', 'Model Y', 'model Y', 'model y', 'Model 3', 'model 3', 'model three', 'Tesla Roadster', 'Tesla roadster', 'tesla roadster', 'Tesla Cybertruck', 'tesla Cybertruck', 'tesla cybertruck', 'Cybertruck', 'cybertruck']\n",
        "pandas_Tesla_2020 = fetch_quotes (pyspark_dfquotes_2020, year = 2020, keyword_list = keywords_2020_Tesla , filename = 'Tesla-quotes-2020.json') # 942  quotes"
      ],
      "metadata": {
        "id": "zVjpAQQ4MMqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907b1910-bbe8-4311-94a2-93c2e6135f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chevrolet 2020\n",
        "keywords_2020_Chevy = ['Chevrolet', 'Silverado', 'Chevrolet Silverado']\n",
        "pandas_Chevy_2020 = fetch_quotes (pyspark_dfquotes_2020, year = 2020, keyword_list = keywords_2020_Chevy , filename = 'Chevy-quotes-2020.json')  # 94 quotes"
      ],
      "metadata": {
        "id": "mstagwfBMMnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b70f78b-fed7-4e76-a569-7601c0aecf4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "reading keywords...\n",
            "filtering the quotes...\n",
            "converting to pandas dataframe...\n",
            "write to compressed json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toyota\n",
        "keywords_2020_Toyota = ['Toyota', 'toyota']\n",
        "pandas_Toyota_2020 = fetch_quotes (pyspark_dfquotes_2020 , year = 2020, keyword_list = keywords_2020_Toyota , filename = 'Toyota-quotes-2020.json') # "
      ],
      "metadata": {
        "id": "ApzOe_GaVjIa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
