{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a46e34b",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f0d8a4-d90f-4123-96f3-544cefad1df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /Users/tatianacogne/opt/anaconda3/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyspark in /Users/tatianacogne/opt/anaconda3/lib/python3.8/site-packages (3.2.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in /Users/tatianacogne/opt/anaconda3/lib/python3.8/site-packages (from pyspark) (0.10.9.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf638b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sf\n",
    "import requests\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6253575d-4142-4eb1-862d-e4fb0502443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/Users/tatianacogne/spark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81a6fb-ee8f-4cb0-a04a-62c3bf2c4a0b",
   "metadata": {},
   "source": [
    "### Objectives M2\n",
    "- That you can handle the data in its size.\n",
    "- That you understand what’s in the data (formats, distributions, missing values, correlations, etc.).\n",
    "- That you considered ways to enrich, filter, transform the data according to your needs.\n",
    "- That you have a reasonable plan and ideas for methods you’re going to use, giving their essential mathematical details in the notebook.\n",
    "- That your plan for analysis and communication is reasonable and sound, potentially discussing alternatives to your choices that you considered but dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ba343",
   "metadata": {},
   "source": [
    "### Test with PySpark\n",
    "https://spark.apache.org/docs/latest/sql-programming-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf03c6d-23aa-4cd7-ae24-151f5eb7daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark context\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Read JSON file into dataframe\n",
    "df = spark.read.json('data/quotes-2020.json.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d283cba-7b6c-4ad7-9f1e-36392f1a5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955b628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+--------------------+--------------------+--------------------+-----------------+-------------------+--------------------+\n",
      "|               date|numOccurrences|phase|              probas|                qids|           quotation|          quoteID|            speaker|                urls|\n",
      "+-------------------+--------------+-----+--------------------+--------------------+--------------------+-----------------+-------------------+--------------------+\n",
      "|2020-01-28 08:04:05|             1|    E|[[None, 0.7272], ...|                  []|[ D ] espite the ...|2020-01-28-000082|               None|[http://israelnat...|\n",
      "|2020-01-16 12:00:13|             1|    E|[[Sue Myrick, 0.8...|           [Q367796]|[ Department of H...|2020-01-16-000088|         Sue Myrick|[http://thehill.c...|\n",
      "|2020-02-10 23:45:54|             1|    E|[[None, 0.8926], ...|                  []|... He (Madhav) a...|2020-02-10-000142|               None|[https://indianex...|\n",
      "|2020-02-15 14:12:51|             2|    E|[[None, 0.581], [...|                  []|... [ I ] f it ge...|2020-02-15-000053|               None|[https://patriotp...|\n",
      "|2020-01-24 20:37:09|             4|    E|[[Meghan King Edm...|         [Q20684375]|[ I met them ] wh...|2020-01-24-000168|Meghan King Edmonds|[https://people.c...|\n",
      "|2020-02-27 08:27:00|             1|    E|[[None, 0.7164], ...|                  []|[ one's ] individ...|2020-02-27-000223|               None|[https://ukhumanr...|\n",
      "|2020-04-15 17:30:45|             1|    E|[[None, 0.8956], ...|                  []|[ Queen ] can. He...|2020-04-15-000176|               None|[https://www.penn...|\n",
      "|2020-01-17 13:03:00|             1|    E|[[Dexter Smith, 0...|          [Q5268447]|[ The delay ] wil...|2020-01-17-000357|       Dexter Smith|[http://www.sloug...|\n",
      "|2020-04-02 14:18:20|             1|    E|[[Barry Coppinger...|          [Q4864119]|[ The scheme ] tr...|2020-04-02-000239|    Barry Coppinger|[http://www.thewe...|\n",
      "|2020-03-19 19:14:00|             1|    E|[[Ben Carson, 0.9...|           [Q816459]|[ These ] actions...|2020-03-19-000276|         Ben Carson|[https://mortgage...|\n",
      "|2020-02-02 16:38:56|             1|    E|[[Danny Davis, 0....|[Q5220272, Q5220273]|... Under a Presi...|2020-02-02-000235|        Danny Davis|[https://chicago....|\n",
      "|2020-04-08 12:25:37|             1|    E|[[None, 0.9208], ...|                  []|[ W ] henever a d...|2020-04-08-000247|               None|[https://www.wash...|\n",
      "|2020-03-10 19:15:22|             1|    E|[[None, 0.7943], ...|                  []|... We deserve a ...|2020-03-10-000380|               None|[https://www.dail...|\n",
      "|2020-03-29 17:47:52|             1|    E|[[None, 0.6976], ...|                  []|... Zane Lowe che...|2020-03-29-000118|               None|[https://music.mx...|\n",
      "|2020-04-06 10:25:55|             1|    E|[[None, 0.9144], ...|                  []|1) Cary hand-bead...|2020-04-06-000292|               None|[http://feeds.inq...|\n",
      "|2020-03-12 19:15:29|             1|    E|[[Paul Masterton,...|         [Q30164281]|1. FM is entitled...|2020-03-12-000358|     Paul Masterton|[http://www.thena...|\n",
      "|2020-01-08 10:22:11|             1|    E|[[Aphelele Fassi,...|         [Q56255401]|11 straight weeks...|2020-01-08-000594|     Aphelele Fassi|[https://www.spor...|\n",
      "|2020-03-20 12:58:41|             1|    E|[[None, 0.6295], ...|                  []|2. Denial of the ...|2020-03-20-000422|               None|[http://itdoffici...|\n",
      "|2020-03-18 15:31:33|             1|    E|[[None, 0.633], [...|                  []|20 people are at ...|2020-03-18-000414|               None|[https://timesofi...|\n",
      "|2020-02-21 13:00:00|             1|    E|[[Micha Kaufman, ...|         [Q26923564]|2019 was a landma...|2020-02-21-000455|      Micha Kaufman|[https://www.fool...|\n",
      "+-------------------+--------------+-----+--------------------+--------------------+--------------------+-----------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c98daf",
   "metadata": {},
   "source": [
    "## A .Understanding of what’s in the data (formats, distributions, missing values, correlations, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb9e28",
   "metadata": {},
   "source": [
    "### A1. Formats of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939bf25",
   "metadata": {},
   "source": [
    "#### Summary Columns\n",
    "- **quoteID**:      Primary key of the quotation (format: \"YYYY-MM-DD-{increasing int:06d}\")\n",
    "- **quotation**:    Text of the longest encountered original form of the quotation\n",
    "- **speaker**:      Selected most likely speaker\n",
    "- **qids**:         Wikidata IDs of all aliases that match the selected speaker\n",
    "- **date**:         Earliest occurrence date of any version of the quotation\n",
    "- **numOccurences**:Number of time this quotation occurs in the articles\n",
    "- **probas**:       Array representing the probabilities of each speaker having uttered the quotation\n",
    "- **urls**:         List of links to the original articles containing the quotation\n",
    "- **phase**:        Corresponding phase of the data in which the quotation first occurred (A-E)\n",
    "- **domains**:      Domain of the URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e4889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- numOccurrences: long (nullable = true)\n",
      " |-- phase: string (nullable = true)\n",
      " |-- probas: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- qids: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- quotation: string (nullable = true)\n",
      " |-- quoteID: string (nullable = true)\n",
      " |-- speaker: string (nullable = true)\n",
      " |-- urls: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fee50",
   "metadata": {},
   "source": [
    "### A2. Distributions\n",
    "- Idea: Distribution of the words ? Or maybe later ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e492a",
   "metadata": {},
   "source": [
    "### A3. Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f1ada",
   "metadata": {},
   "source": [
    "### A4. Correlation\n",
    "- Idea: slides du cours ? Je ne sais pas si on doit déjà commencer à faire ce genre d'analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db883ba",
   "metadata": {},
   "source": [
    "## B. Ways to enrich, filter, transform the data according to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8164f58",
   "metadata": {},
   "source": [
    "### B1. Task\n",
    "- Quotes: need to use different functions in order filter the quotes before analyzing\n",
    "    - remove stop words (and, the, ...)\n",
    "    - stemming and lemming the quotes\n",
    "    - use NLTK function in order to categorize the words in the sentence for example\n",
    "- Speakers: \n",
    "    - need to keep only the speakers different form \"None\"\n",
    "        - is it resonnable tp drop the None speakers ? Not a too big percentage of the dataset ? \n",
    "    - need to regroup speakers like \"President Donald Trump\" and \"Donald Trump\"\n",
    "    - add columns with the occupations/jobs of the speakers maybe in a new column (Obama : politician,lawyer,author)\n",
    "- QIDS:  \n",
    "    - add the link to the wikipedia page of the speaker\n",
    "    - keep only the qids of the speaker\n",
    "        - need to check if everything OK with the qids (qids speaker =?= speaker)\n",
    "- Date:\n",
    "    - Try to keep only the important informations about the date (maybe don't need to keep the minutes)\n",
    "- Removes columns that we do not need (quotesID, phase, ...?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f06cfa1",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "\n",
    "- quids same for each quote \n",
    "- check proba avec le speaker \n",
    "- check chaque colonne\n",
    "- verifier l'URL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ea5d9",
   "metadata": {},
   "source": [
    "**Analysing Selected Speaker vs Highest Probablity Speaker**\n",
    "\n",
    "Comparing the speaker in the \"speaker\" column against the one with the highest probability in \"probas\", outputing the lines with different values for those two, and counting the number of occurences, displaying the highest ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e76fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+--------------------+\n",
      "|          speaker|              probas|        highest_prob|        prob_speaker|\n",
      "+-----------------+--------------------+--------------------+--------------------+\n",
      "|             None|[[Kris Bryant, 0....|[Kris Bryant, 0.4...|         Kris Bryant|\n",
      "|         Jane Roe|[[None, 0.2695], ...|      [None, 0.2695]|                None|\n",
      "| Christian Doidge|[[None, 0.1002], ...|      [None, 0.1002]|                None|\n",
      "|     Heidi Larson|[[None, 0.0614], ...|      [None, 0.0614]|                None|\n",
      "|             None|[[Rio Ferdinand, ...|[Rio Ferdinand, 0...|       Rio Ferdinand|\n",
      "|             None|[[Paul Brown, 0.3...|[Paul Brown, 0.3887]|          Paul Brown|\n",
      "|     Joel Dommett|[[None, 0.0367], ...|      [None, 0.0367]|                None|\n",
      "|        Ed Turner|[[None, 0.0172], ...|      [None, 0.0172]|                None|\n",
      "|      Peter Weber|[[None, 0.3477], ...|      [None, 0.3477]|                None|\n",
      "|             None|[[Chasson Randle,...|[Chasson Randle, ...|      Chasson Randle|\n",
      "|      Matt Barnes|[[None, 0.3548], ...|      [None, 0.3548]|                None|\n",
      "|      Pamela Dale|[[None, 0.389], [...|       [None, 0.389]|                None|\n",
      "|    Toby Emmerich|[[None, 0.0866], ...|      [None, 0.0866]|                None|\n",
      "|  Kelvin Fletcher|[[None, 0.1521], ...|      [None, 0.1521]|                None|\n",
      "|    Meghan Markle|[[None, 0.3556], ...|      [None, 0.3556]|                None|\n",
      "|   Bernie Sanders|[[None, 0.079], [...|       [None, 0.079]|                None|\n",
      "|Charles Gillibert|[[Kirill Serebren...|[Kirill Serebrenn...|Kirill Serebrennikov|\n",
      "|   Karen Williams|[[None, 0.133], [...|       [None, 0.133]|                None|\n",
      "|             None|[[Princess Beatri...|[Princess Beatric...|   Princess Beatrice|\n",
      "|       Brian Ford|[[None, 0.0353], ...|      [None, 0.0353]|                None|\n",
      "+-----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = df.select(df.speaker, df.probas)\n",
    "temp = temp.withColumn(\"highest_prob\", temp.probas[0])\n",
    "temp = temp.withColumn(\"prob_speaker\", temp.highest_prob[0])\n",
    "\n",
    "error_speakers = temp.filter(temp.speaker != temp.prob_speaker).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2f1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "WrongSpeakers = temp.groupBy(\"prob_speaker\").count().withColumnRenamed(\"prob_speaker\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac363edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_wrong = WrongSpeakers.sort(\"count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58163e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_wrong.toPandas().to_csv('speakers_count_19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce39b1",
   "metadata": {},
   "source": [
    "**Analysing Columns**\n",
    "\n",
    "Checking for aberrent values in the dataset, each column separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51cc639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "|date|numOccurrences|phase|probas|qids|quotation|quoteID|speaker|urls|\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "+----+--------------+-----+------+----+---------+-------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.date == None).show()\n",
    "df.filter(df.numOccurrences == None).show()\n",
    "df.filter(df.phase == None).show()\n",
    "df.filter(df.probas == None).show()\n",
    "df.filter(df.qids == None).show()\n",
    "df.filter(df.quotation == None).show()\n",
    "df.filter(df.quoteID == None).show()\n",
    "df.filter(df.speaker == None).show()\n",
    "df.filter(df.urls == None).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6891334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker\n",
    "df_speakers =df.drop_duplicates(subset=['speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75a7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diff_speakers = df_speakers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c34d8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = df_speakers[['speaker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9df13bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_none = df[df.speaker=='None']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6d02d",
   "metadata": {},
   "source": [
    "# Note - problem with this cell : Can't extract value from speaker#14: need struct type but got string\n",
    "df[df['speaker'].str.contains('pokemon')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07b723",
   "metadata": {},
   "source": [
    "**Analysing Number of Occurences**\n",
    "\n",
    "Looking at the most occuring Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_occurences = df.sort(\"numOccurrences\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7866f8",
   "metadata": {},
   "source": [
    "#### Analysis on speakers \n",
    "- Number of different speakers : 218415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259164eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cffb4dc13a2c8d65c4e22bea49294395e13ba2eea796238c356a7a0a6291307b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
