{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a46e34b",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf638b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sf\n",
    "import requests\n",
    "import findspark\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ba343",
   "metadata": {},
   "source": [
    "### PySpark\n",
    "Since the datasets have an important size, we've decided to use pyspark in order to parse or analyze the data. Sometimes we only focus on some columns so we can \"go back\" to pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf03c6d-23aa-4cd7-ae24-151f5eb7daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark context\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6cdf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON file and put it in a pyspark dataframe.\n",
    "df = spark.read.json('data/quotes-2020.json.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955b628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+--------------------+-----------+--------------------+-----------------+-------------------+--------------------+\n",
      "|               date|numOccurrences|phase|              probas|       qids|           quotation|          quoteID|            speaker|                urls|\n",
      "+-------------------+--------------+-----+--------------------+-----------+--------------------+-----------------+-------------------+--------------------+\n",
      "|2020-01-28 08:04:05|             1|    E|[[None, 0.7272], ...|         []|[ D ] espite the ...|2020-01-28-000082|               None|[http://israelnat...|\n",
      "|2020-01-16 12:00:13|             1|    E|[[Sue Myrick, 0.8...|  [Q367796]|[ Department of H...|2020-01-16-000088|         Sue Myrick|[http://thehill.c...|\n",
      "|2020-02-10 23:45:54|             1|    E|[[None, 0.8926], ...|         []|... He (Madhav) a...|2020-02-10-000142|               None|[https://indianex...|\n",
      "|2020-02-15 14:12:51|             2|    E|[[None, 0.581], [...|         []|... [ I ] f it ge...|2020-02-15-000053|               None|[https://patriotp...|\n",
      "|2020-01-24 20:37:09|             4|    E|[[Meghan King Edm...|[Q20684375]|[ I met them ] wh...|2020-01-24-000168|Meghan King Edmonds|[https://people.c...|\n",
      "+-------------------+--------------+-----+--------------------+-----------+--------------------+-----------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb9e28",
   "metadata": {},
   "source": [
    "### Formats of the data\n",
    "#### Summary Columns\n",
    "- **quoteID**:      Primary key of the quotation (format: \"YYYY-MM-DD-{increasing int:06d}\")\n",
    "- **quotation**:    Text of the longest encountered original form of the quotation\n",
    "- **speaker**:      Selected most likely speaker\n",
    "- **qids**:         Wikidata IDs of all aliases that match the selected speaker\n",
    "- **date**:         Earliest occurrence date of any version of the quotation\n",
    "- **numOccurences**:Number of time this quotation occurs in the articles\n",
    "- **probas**:       Array representing the probabilities of each speaker having uttered the quotation\n",
    "- **urls**:         List of links to the original articles containing the quotation\n",
    "- **phase**:        Corresponding phase of the data in which the quotation first occurred (A-E)\n",
    "- **domains**:      Domain of the URL \n",
    "\n",
    "We can see using the printSchema function the description of each columns (name, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e4889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- numOccurrences: long (nullable = true)\n",
      " |-- phase: string (nullable = true)\n",
      " |-- probas: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- qids: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- quotation: string (nullable = true)\n",
      " |-- quoteID: string (nullable = true)\n",
      " |-- speaker: string (nullable = true)\n",
      " |-- urls: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db078b",
   "metadata": {},
   "source": [
    "An interesting view to have is the overall distribution of speakers, and which are the most represented, by counting thier number of occurences.\n",
    "\n",
    "We want to analyse whether there are errors in the columns, that would show if a null value would appear in one of the columns. Thus, we check each column for such an error. However, we do not check the Speakers column, it is natural to find None values, occuring when Quootstrap did not find an appropriate speaker for the quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.date == None).show()\n",
    "df.filter(df.numOccurrences == None).show()\n",
    "df.filter(df.phase == None).show()\n",
    "df.filter(df.probas == None).show()\n",
    "df.filter(df.qids == None).show()\n",
    "df.filter(df.quotation == None).show()\n",
    "df.filter(df.quoteID == None).show()\n",
    "df.filter(df.speaker == None).show()\n",
    "df.filter(df.urls == None).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c2a6a",
   "metadata": {},
   "source": [
    "However, a way to check the integrity of the speakers is to compare the attributed speaker to the one with the highest probability as indicated in the probas column. In the meantime, we compare the ditribution of the overall speakers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57577a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.select(df.speaker, df.probas)\n",
    "temp = temp.withColumn(\"highest_prob\", temp.probas[0])\n",
    "temp = temp.withColumn(\"prob_speaker\", temp.highest_prob[0])\n",
    "\n",
    "error_speakers = temp.filter(temp.speaker != temp.prob_speaker)\n",
    "error_speakers.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WrongSpeakers = error_speakers.groupBy(\"prob_speaker\").count()\n",
    "asc_wrong = WrongSpeakers.sort(\"count\", ascending = False)\n",
    "\n",
    "overall_speakers = temp.groupBy(\"prob_speaker\").count()\n",
    "asc_overall = overall_speakers.sort(\"count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = asc_overall.toPandas()\n",
    "wrong = asc_wrong.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = overall[1:11]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(overall[\"prob_speaker\"], overall[\"count\"], color = 'r', ec='black')\n",
    "plt.xlabel('Speaker')\n",
    "plt.xticks(rotation = \"vertical\")\n",
    "plt.ylabel('Frequency [Number of citation]')\n",
    "plt.title('Distribution of the most cited people in the dataset overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = wrong[1:11]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(wrong[\"prob_speaker\"], wrong[\"count\"], color = 'r', ec='black')\n",
    "plt.xlabel('Speaker')\n",
    "plt.xticks(rotation = \"vertical\")\n",
    "plt.ylabel('Frequency [Number of citation]')\n",
    "plt.title('Distribution of the most cited people in the dataset in misatributed speakers ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25e2e5",
   "metadata": {},
   "source": [
    "As we can expect, the most cited speakers are ones that are the most talked about depending on the events of the year. In the 2020 dataset, we find the quotes relating to the american elections, and we see that the most cited speakers are almost all the ones more or less related to them, exept for Narendra Modi, most likely appearing because of the global unrest in india during 2020.\n",
    "As far as the \"misslabeled\" datapoints, we do not see any specific pattern. Every speaker that is misslabeled is so only once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95079f93",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "In order to analyse the statistics of some columns we used the function summary. We only kept the statics that are relevants. For the example the percentiles are not really meaningful for the quotation since the column contain only words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d948c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    numOccurrences|\n",
      "+-------+------------------+\n",
      "|  count|           5244449|\n",
      "|   mean|3.2820887380161388|\n",
      "| stddev|13.983172414380137|\n",
      "|    min|                 1|\n",
      "|    25%|                 1|\n",
      "|    50%|                 1|\n",
      "|    75%|                 2|\n",
      "|    max|              9210|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Est ce que cette ligne pourrait être utile ? \n",
    "df.select('numOccurrences').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d367f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+-------+--------------------+-----------------+----------------+\n",
      "|summary|               date|    numOccurrences|  phase|           quotation|          quoteID|         speaker|\n",
      "+-------+-------------------+------------------+-------+--------------------+-----------------+----------------+\n",
      "|  count|            5244449|           5244449|5244449|             5244449|          5244449|         5244449|\n",
      "|   mean|               null|3.2820887380161388|   null|                null|             null|            null|\n",
      "| stddev|               null|13.983172414380137|   null|                null|             null|            null|\n",
      "|    min|2020-01-01 00:00:00|                 1|      E|! -- I am Jesus, ...|2020-01-01-000001|( Sandy ) Alex G|\n",
      "|    25%|               null|                 1|   null|                null|             null|            null|\n",
      "|    50%|               null|                 1|   null|                null|             null|            null|\n",
      "|    75%|               null|                 2|   null|                null|             null|            null|\n",
      "|    max|2020-04-17 12:04:53|              9210|      E|￼ ￼ My opinion, I...|2020-04-17-000613|   Željana Zovko|\n",
      "+-------+-------------------+------------------+-------+--------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db883ba",
   "metadata": {},
   "source": [
    "### Ways to enrich, filter, transform the data.\n",
    "#### Task\n",
    "We tried to list some of the tasks/transformations that we need to do in order to go thourgh the project. \n",
    "- Quotes: For the moment, the quotes are \"just\" sentence and we need to use different process in order to clean it for the purpose of the project.\n",
    "    - remove stop words (and, the, ...)\n",
    "    - stemming and lemming the quotes\n",
    "    - use NLTK function in order to categorize the words in the sentence for example\n",
    "- Speakers: With the dataframe summary we can see that there is 5,244,449 speakers only for the 2020's dataset. It seems to be a large number and we need to look more into detail this columns. For the project we might need also to add to features about the speakers, for the example it's occupations\n",
    "    - First we only keep the speakers that are not \"None\"\n",
    "    - See if a person has multiple names and decide how we want to proceed.\n",
    "    - Add features about the speakers using the file speaker_attributes.parquet\n",
    "- Date and quoteID: We noticed that the date and the quoteID columns have maybe information that are not relevant for our project. \n",
    "    - The date contains for each row the minute and the seconds, we could try to cut the date into a smaller size by removing them\n",
    "    - The quoteID have the format : year-month-day-number. We need to transform this column in order to keep only the relevant informations. \n",
    "- Finally, it might interesting to remove columns that we do not need (quotesID, phase, ...). It could reduce the size of the dataset considerably"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173fa32",
   "metadata": {},
   "source": [
    "To simplify the tasks, we will use a specific event that will allow us to compute faster and try our methods. We take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_australia = df.filter(df.quotation.contains('Parasite')).limit(2400)\n",
    "df_australia.show()\n",
    "\n",
    "australia = df_australia.toPandas()\n",
    "australia_words = australia.iloc[:,5]\n",
    "\n",
    "splitted = []\n",
    "\n",
    "for sub in australia_words:\n",
    "    for wrd in sub.split():\n",
    "        splitted.append(wrd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb17cb4",
   "metadata": {},
   "source": [
    "At the level of Quotes, since we want to capture the essence of the words, we need to filter a bit the data. First, we will need to get rid of the \"common\" words that do not contribute much to the actual meaning of the sentence and have a risk of overshadowing the relevant information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_aust = Counter(temp)\n",
    "most_occur = counter_aust.most_common(100)\n",
    "  \n",
    "print(most_occur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117105c1",
   "metadata": {},
   "source": [
    "We see that indeed, even in this small subset, we have predominant nonimportant words. To then extract relevant words, we can use the TF-IDF method, which is an information retrieval technique that produces a value that increases depending on how many time it is cited in a document, but also decreases the more it is present in different documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f12c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(filtered_sentence)\n",
    "\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a0ea5",
   "metadata": {},
   "source": [
    "We see that we have some interesting information, but still have quite a large amount of words. We might need to filter accoring to specific criteria to direct the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386bc637",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea46938",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentence = [w for w in splitted if not w.lower() in stop_words]\n",
    "print(\"There are in the unfiltered subset:\",len(splitted), \"words\")\n",
    "print(\"There are in the filtered subset:\", len(filtered_sentence), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "pos_quotes = []\n",
    "neg_quotes = []\n",
    "\n",
    "for i in range(0, len(australia_words)):\n",
    "    \n",
    "    humor = sia.polarity_scores(australia_words[i])\n",
    "    if humor[\"pos\"] > 0.4:\n",
    "        pos_quotes.append(australia_words[i])\n",
    "    elif humor[\"neg\"] > 0.4:\n",
    "        neg_quotes.append(australia_words[i])\n",
    "\n",
    "print(\"The mostly positive quotes are:\", pos_quotes)\n",
    "print(\"The mostly negative quotes are:\", neg_quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4494190",
   "metadata": {},
   "source": [
    "A popular method to extract relevance of words in a corpus is TF-IDF. This method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5cfdc8",
   "metadata": {},
   "source": [
    "A useful tool is the Natural Language ToolKit, which implemented various functions destined to process language, which we can take advantage of. For example, we need to filter common words such as coordinations that blur the processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034adece",
   "metadata": {},
   "source": [
    "We see that though it is quite basic, it gives a good idea of the feeling of certain quotes. Given that it is possible to \"improve\" VADER, for example depending on the events we can find new words associated with negative and positive emotions, to help it recognize the sentences in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ea5d9",
   "metadata": {},
   "source": [
    "**Analysing Selected Speaker vs Highest Probablity Speaker**\n",
    "\n",
    "Comparing the speaker in the \"speaker\" column against the one with the highest probability in \"probas\", outputing the lines with different values for those two, and counting the number of occurences, displaying the highest ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce39b1",
   "metadata": {},
   "source": [
    "**Analysing Columns**\n",
    "\n",
    "Checking for aberrent values in the dataset, each column separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6891334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker\n",
    "df_speakers =df.drop_duplicates(subset=['speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diff_speakers = df_speakers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = df_speakers[['speaker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df13bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_none = df[df.speaker=='None']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07b723",
   "metadata": {},
   "source": [
    "**Analysing Number of Occurences**\n",
    "\n",
    "Looking at the most occuring Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d03b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_occurences = df.sort(\"numOccurrences\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4749bc",
   "metadata": {},
   "source": [
    "#### First analysis of the speaker column\n",
    "We first started be creating a file containing only the speakers. The we loaded the new file in a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c04412f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'data/quotes-2020.json.bz2' \n",
    "path_to_out = 'data/speakers-2020.txt.bz2'\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wt') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            speaker = sp = instance['speaker']\n",
    "            if sp[0] != 'None':\n",
    "                d_file.write(speaker+'\\n')# writing in the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259164eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sue Myrick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meghan King Edmonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dexter Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Barry Coppinger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ben Carson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243953</th>\n",
       "      <td>Jackie Northam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244009</th>\n",
       "      <td>Taavi Rõivas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244044</th>\n",
       "      <td>Yu Jin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244161</th>\n",
       "      <td>Eoin McGrath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244413</th>\n",
       "      <td>Tjungkara Ken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218414 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "1                 Sue Myrick\n",
       "4        Meghan King Edmonds\n",
       "7               Dexter Smith\n",
       "8            Barry Coppinger\n",
       "9                 Ben Carson\n",
       "...                      ...\n",
       "5243953       Jackie Northam\n",
       "5244009         Taavi Rõivas\n",
       "5244044               Yu Jin\n",
       "5244161         Eoin McGrath\n",
       "5244413        Tjungkara Ken\n",
       "\n",
       "[218414 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_speaker = pd.read_csv('data/speakers-2020.txt.bz2', sep=\"\\n\", header=None)\n",
    "data_speaker = data_speaker[data_speaker[0] !='None'].drop_duplicates()\n",
    "data_speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357531d2",
   "metadata": {},
   "source": [
    "There is for the 2020's dataset, 218,414 different speakers, it seems to be still a big number. We decided to look more into detail. We used Donald Trump as an example to begin our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c85748ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>President Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>President Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13688</th>\n",
       "      <td>Donald Trump Jr. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15578</th>\n",
       "      <td>Donald Trump Jr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16328</th>\n",
       "      <td>Donald Trump , Jr. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16448</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27659</th>\n",
       "      <td>President Donald J. Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31087</th>\n",
       "      <td>Donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38768</th>\n",
       "      <td>president Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48869</th>\n",
       "      <td>president trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53023</th>\n",
       "      <td>DONALD Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61403</th>\n",
       "      <td>PRESIDENT DONALD TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71825</th>\n",
       "      <td>DONALD TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212600</th>\n",
       "      <td>President trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223419</th>\n",
       "      <td>donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226235</th>\n",
       "      <td>Donald J Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243582</th>\n",
       "      <td>PRESIDENT Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244303</th>\n",
       "      <td>president Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300995</th>\n",
       "      <td>Donald John Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343733</th>\n",
       "      <td>PRESIDENT Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660915</th>\n",
       "      <td>PRESIDENT TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679182</th>\n",
       "      <td>President DOnald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706650</th>\n",
       "      <td>President DONALD TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770766</th>\n",
       "      <td>President Donald John Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914264</th>\n",
       "      <td>donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403454</th>\n",
       "      <td>president donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856351</th>\n",
       "      <td>donald trump jr. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864746</th>\n",
       "      <td>DONALD TRUMP JR. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857464</th>\n",
       "      <td>President Donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196302</th>\n",
       "      <td>president Donald J. Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364670</th>\n",
       "      <td>PRESIDENT DONALD Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825011</th>\n",
       "      <td>President donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270472</th>\n",
       "      <td>DONALD TRUMP JR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958098</th>\n",
       "      <td>president Donald John Trump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0\n",
       "247                     Donald Trump\n",
       "263           President Donald Trump\n",
       "609                  President Trump\n",
       "13688             Donald Trump Jr. .\n",
       "15578                Donald Trump Jr\n",
       "16328           Donald Trump , Jr. .\n",
       "16448                Donald J. Trump\n",
       "27659      President Donald J. Trump\n",
       "31087                   Donald trump\n",
       "38768         president Donald Trump\n",
       "48869                president trump\n",
       "53023                   DONALD Trump\n",
       "61403         PRESIDENT DONALD TRUMP\n",
       "71825                   DONALD TRUMP\n",
       "212600               President trump\n",
       "223419                  donald trump\n",
       "226235                Donald J Trump\n",
       "243582        PRESIDENT Donald Trump\n",
       "244303               president Trump\n",
       "300995             Donald John Trump\n",
       "343733               PRESIDENT Trump\n",
       "660915               PRESIDENT TRUMP\n",
       "679182        President DOnald Trump\n",
       "706650        President DONALD TRUMP\n",
       "770766   President Donald John Trump\n",
       "914264                  donald Trump\n",
       "1403454       president donald trump\n",
       "1856351           donald trump jr. .\n",
       "1864746           DONALD TRUMP JR. .\n",
       "2857464       President Donald trump\n",
       "3196302    president Donald J. Trump\n",
       "3364670       PRESIDENT DONALD Trump\n",
       "3825011       President donald trump\n",
       "4270472              DONALD TRUMP JR\n",
       "4958098  president Donald John Trump"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trump = data_speaker.loc[data_speaker[0].str.contains('Trump',case = False)]\n",
    "df_trump = df_trump.drop_duplicates()\n",
    "searchfor = ['Melania', 'Eric','Ivanka','judd','trumpauer','Barron','Lara','Andreas','william','trumper','spencer','blaine','charles','ivana']\n",
    "df_trump = df_trump[~df_trump[0].str.contains('|'.join(searchfor),case = False)]\n",
    "df_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a3f8844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+--------------------+-------------------+--------------------+-----------------+--------------------+--------------------+\n",
      "|               date|numOccurrences|phase|              probas|               qids|           quotation|          quoteID|             speaker|                urls|\n",
      "+-------------------+--------------+-----+--------------------+-------------------+--------------------+-----------------+--------------------+--------------------+\n",
      "|2020-03-03 00:00:00|             1|    E|[[donald Trump, 0...|[Q22686, Q27947481]|We need to have h...|2020-03-03-070897|        donald Trump|[http://kut.org/p...|\n",
      "|2020-03-24 21:59:21|             1|    E|[[president Donal...|           [Q22686]|As we near the en...|2020-03-24-006609|president Donald ...|[https://boingboi...|\n",
      "+-------------------+--------------+-----+--------------------+-------------------+--------------------+-----------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[df.speaker.isin('president Donald John Trump','donald Trump')].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67806bf6",
   "metadata": {},
   "source": [
    "There are 35 different names for Donald Trump, in lower and upper cases. If we want, we could try to \"clean\" this problem but it would take too much time and it would be only for the aesthetic side. The good news is that all the different names for Donald Trump have the same QIDS. We will then use this column for any future analysis or comparison/joining we need to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6a0fc",
   "metadata": {},
   "source": [
    "A second thing that we wanted to analyse is if there were speakers name that we \"not normal\". For this we check for speakers name that contain speacial character and also speakers name that have a size longer than usual (~might be a sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9aca2d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149342</th>\n",
       "      <td>Sister Teresa Joseph Patrick of Jesus and Mary</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945236</th>\n",
       "      <td>Hey That 's No Way to Say Goodbye</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  len\n",
       "149342   Sister Teresa Joseph Patrick of Jesus and Mary    8\n",
       "1945236               Hey That 's No Way to Say Goodbye    8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_speaker['len'] = data_speaker[0].apply(lambda x : len(x.split()))\n",
    "data_speaker[data_speaker['len'] >= 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1feacbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+--------------------+-----------+--------------------+-----------------+--------------------+--------------------+\n",
      "|               date|numOccurrences|phase|              probas|       qids|           quotation|          quoteID|             speaker|                urls|\n",
      "+-------------------+--------------+-----+--------------------+-----------+--------------------+-----------------+--------------------+--------------------+\n",
      "|2020-03-25 17:20:05|             1|    E|[[Hey That 's No ...|[Q27942120]|Never trust the M...|2020-03-25-047483|Hey That 's No Wa...|[https://www.theg...|\n",
      "|2020-03-25 17:20:05|             1|    E|[[Hey That 's No ...|[Q27942120]|I still believe i...|2020-03-25-027071|Hey That 's No Wa...|[https://www.theg...|\n",
      "|2020-03-25 17:20:05|             1|    E|[[Hey That 's No ...|[Q27942120]|I'd hitch hike ar...|2020-03-25-030221|Hey That 's No Wa...|[https://www.theg...|\n",
      "|2020-03-25 17:20:05|             1|    E|[[Hey That 's No ...|[Q27942120]|My cosmic husband...|2020-03-25-046527|Hey That 's No Wa...|[https://www.theg...|\n",
      "+-------------------+--------------+-----+--------------------+-----------+--------------------+-----------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[df.speaker == \"Hey That 's No Way to Say Goodbye\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "424c150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16887</th>\n",
       "      <td>Philip `` Brave '' Davis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18367</th>\n",
       "      <td>Nicole `` Snooki '' Polizzi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28771</th>\n",
       "      <td>Steve `` Lips '' Kudlow</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30179</th>\n",
       "      <td>Kent `` Smallzy '' Small</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50412</th>\n",
       "      <td>Jake `` The Snake '' Roberts</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152740</th>\n",
       "      <td>`` Rowdy '' Roddy Piper</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283614</th>\n",
       "      <td>Jim `` The Anvil '' Neidhart</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4473694</th>\n",
       "      <td>Judd `` Chip '' Lynn</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713229</th>\n",
       "      <td>Leon `` Ndugu '' Chancler</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115428</th>\n",
       "      <td>Mike `` The Truth '' Jackson</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0  len\n",
       "16887        Philip `` Brave '' Davis    5\n",
       "18367     Nicole `` Snooki '' Polizzi    5\n",
       "28771         Steve `` Lips '' Kudlow    5\n",
       "30179        Kent `` Smallzy '' Small    5\n",
       "50412    Jake `` The Snake '' Roberts    6\n",
       "...                               ...  ...\n",
       "4152740       `` Rowdy '' Roddy Piper    5\n",
       "4283614  Jim `` The Anvil '' Neidhart    6\n",
       "4473694          Judd `` Chip '' Lynn    5\n",
       "4713229     Leon `` Ndugu '' Chancler    5\n",
       "5115428  Mike `` The Truth '' Jackson    6\n",
       "\n",
       "[82 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speacial_cases = data_speaker.loc[data_speaker[0].str.contains(\"''\",case = False)].drop_duplicates()\n",
    "df_speacial_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f4e347",
   "metadata": {},
   "source": [
    "We found the speaker \"Hey That 's No Way to Say Goodbye\". The first thing we can see is that it is a sentence. However we notice that this speaker has a QIDS and if we search on google its QIDS we discover that it is a song written by Leonard Cohen. We will then have to take into account in our analysis that sometimes the speakers are not necessarily real people and may have to do an additional filtering.\n",
    "It seems Some speakers name contain speacial character that could be removed but it's again something more \"esthetic\" than pratical for our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5284b7",
   "metadata": {},
   "source": [
    "We have modified the given code to take for example only the name of the speaker, his QIDS, the quote in order to reduce the size of the dataset we would like to analyze. This will allow us to go faster too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'data/quotes-2020.json.bz2' \n",
    "path_to_out = 'data/sp_qids_quotes-2020.txt.bz2'\n",
    "k =0\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wt') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            sp = sp = [instance['speaker'],instance['qids'],instance['quotation']]\n",
    "            if sp[0] != 'None':\n",
    "                d_file.write(sp[0]+'\\t'+sp[1][0]+'\\t'+sp[2]+'\\n')# writing in the new file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e498b",
   "metadata": {},
   "source": [
    "Now we load the speaker_attributes.parquet file to find more information about the speakers. We notice that often in the columns there are not words but once again QIDS. We tried to find the \"labels\" (as defined on Wikidata) of these QIDS but without success. This is an important step in our project, especially to be able to interpret our results because the rest of the time, the analysis can easily be done with the QIDS as for the speakers' QIDS for example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baf6f445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>lastrevid</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>US_congress_bio_ID</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>type</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Washington, President Washington, G. Washingt...</td>\n",
       "      <td>[+1732-02-22T00:00:00Z]</td>\n",
       "      <td>[Q161885, Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1395141751</td>\n",
       "      <td>None</td>\n",
       "      <td>W000178</td>\n",
       "      <td>[Q82955, Q189290, Q131512, Q1734662, Q294126, ...</td>\n",
       "      <td>[Q327591]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q23</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[Q698073, Q697949]</td>\n",
       "      <td>item</td>\n",
       "      <td>[Q682443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Douglas Noel Adams, Douglas Noël Adams, Dougl...</td>\n",
       "      <td>[+1952-03-11T00:00:00Z]</td>\n",
       "      <td>[Q145]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1395737157</td>\n",
       "      <td>[Q7994501]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q214917, Q28389, Q6625963, Q4853732, Q1884422...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q42</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Paul Marie Ghislain Otlet, Paul Marie Otlet]</td>\n",
       "      <td>[+1868-08-23T00:00:00Z]</td>\n",
       "      <td>[Q31]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1380367296</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q36180, Q40348, Q182436, Q1265807, Q205375, Q...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q1868</td>\n",
       "      <td>Paul Otlet</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[George Walker Bush, Bush Jr., Dubya, GWB, Bus...</td>\n",
       "      <td>[+1946-07-06T00:00:00Z]</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1395142029</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955, Q15982858, Q18814623, Q1028181, Q1408...</td>\n",
       "      <td>[Q29468]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q207</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>[Q327959, Q464075, Q3586276, Q4450587]</td>\n",
       "      <td>item</td>\n",
       "      <td>[Q329646, Q682443, Q33203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Velázquez, Diego Rodríguez de Silva y Velázqu...</td>\n",
       "      <td>[+1599-06-06T00:00:00Z]</td>\n",
       "      <td>[Q29]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1391704596</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q1028181]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q297</td>\n",
       "      <td>Diego Velázquez</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Augusto Pinochet Ugarte, Augusto José Ramón P...</td>\n",
       "      <td>[+1915-11-25T00:00:00Z]</td>\n",
       "      <td>[Q298]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1392242213</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q189290, Q82955]</td>\n",
       "      <td>[Q327591]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q368</td>\n",
       "      <td>Augusto Pinochet</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>[Q1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Baudelaire, Charles Pierre Baudelaire-Dufaÿs,...</td>\n",
       "      <td>[+1821-04-09T00:00:00Z]</td>\n",
       "      <td>[Q142]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1386699038</td>\n",
       "      <td>[Q121842]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q49757, Q4164507, Q11774202, Q333634, Q36180,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q501</td>\n",
       "      <td>Charles Baudelaire</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>[Q1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Mikołaj Kopernik, Nikolaus Kopernikus, Copern...</td>\n",
       "      <td>[+1473-02-19T00:00:00Z]</td>\n",
       "      <td>[Q1649871]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1394975677</td>\n",
       "      <td>[Q1026]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q11063, Q185351, Q188094, Q170790, Q16012028,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q619</td>\n",
       "      <td>Nicolaus Copernicus</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>[Q1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Neil Percival Young, Shakey, Godfather of Gru...</td>\n",
       "      <td>[+1945-11-12T00:00:00Z]</td>\n",
       "      <td>[Q16, Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1395459626</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q177220, Q488205, Q2526255, Q639669, Q1881462...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q633</td>\n",
       "      <td>Neil Young</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>[+1969-00-00T00:00:00Z]</td>\n",
       "      <td>[Q183]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1340253739</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q33231, Q41546637]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q640</td>\n",
       "      <td>Harald Krichel</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             aliases            date_of_birth  \\\n",
       "0  [Washington, President Washington, G. Washingt...  [+1732-02-22T00:00:00Z]   \n",
       "1  [Douglas Noel Adams, Douglas Noël Adams, Dougl...  [+1952-03-11T00:00:00Z]   \n",
       "2      [Paul Marie Ghislain Otlet, Paul Marie Otlet]  [+1868-08-23T00:00:00Z]   \n",
       "3  [George Walker Bush, Bush Jr., Dubya, GWB, Bus...  [+1946-07-06T00:00:00Z]   \n",
       "4  [Velázquez, Diego Rodríguez de Silva y Velázqu...  [+1599-06-06T00:00:00Z]   \n",
       "5  [Augusto Pinochet Ugarte, Augusto José Ramón P...  [+1915-11-25T00:00:00Z]   \n",
       "6  [Baudelaire, Charles Pierre Baudelaire-Dufaÿs,...  [+1821-04-09T00:00:00Z]   \n",
       "7  [Mikołaj Kopernik, Nikolaus Kopernikus, Copern...  [+1473-02-19T00:00:00Z]   \n",
       "8  [Neil Percival Young, Shakey, Godfather of Gru...  [+1945-11-12T00:00:00Z]   \n",
       "9                                               None  [+1969-00-00T00:00:00Z]   \n",
       "\n",
       "      nationality      gender   lastrevid ethnic_group US_congress_bio_ID  \\\n",
       "0  [Q161885, Q30]  [Q6581097]  1395141751         None            W000178   \n",
       "1          [Q145]  [Q6581097]  1395737157   [Q7994501]               None   \n",
       "2           [Q31]  [Q6581097]  1380367296         None               None   \n",
       "3           [Q30]  [Q6581097]  1395142029         None               None   \n",
       "4           [Q29]  [Q6581097]  1391704596         None               None   \n",
       "5          [Q298]  [Q6581097]  1392242213         None               None   \n",
       "6          [Q142]  [Q6581097]  1386699038    [Q121842]               None   \n",
       "7      [Q1649871]  [Q6581097]  1394975677      [Q1026]               None   \n",
       "8      [Q16, Q30]  [Q6581097]  1395459626         None               None   \n",
       "9          [Q183]  [Q6581097]  1340253739         None               None   \n",
       "\n",
       "                                          occupation      party  \\\n",
       "0  [Q82955, Q189290, Q131512, Q1734662, Q294126, ...  [Q327591]   \n",
       "1  [Q214917, Q28389, Q6625963, Q4853732, Q1884422...       None   \n",
       "2  [Q36180, Q40348, Q182436, Q1265807, Q205375, Q...       None   \n",
       "3  [Q82955, Q15982858, Q18814623, Q1028181, Q1408...   [Q29468]   \n",
       "4                                         [Q1028181]       None   \n",
       "5                                  [Q189290, Q82955]  [Q327591]   \n",
       "6  [Q49757, Q4164507, Q11774202, Q333634, Q36180,...       None   \n",
       "7  [Q11063, Q185351, Q188094, Q170790, Q16012028,...       None   \n",
       "8  [Q177220, Q488205, Q2526255, Q639669, Q1881462...       None   \n",
       "9                                [Q33231, Q41546637]       None   \n",
       "\n",
       "  academic_degree     id                label  \\\n",
       "0            None    Q23    George Washington   \n",
       "1            None    Q42        Douglas Adams   \n",
       "2            None  Q1868           Paul Otlet   \n",
       "3            None   Q207       George W. Bush   \n",
       "4            None   Q297      Diego Velázquez   \n",
       "5            None   Q368     Augusto Pinochet   \n",
       "6            None   Q501   Charles Baudelaire   \n",
       "7            None   Q619  Nicolaus Copernicus   \n",
       "8            None   Q633           Neil Young   \n",
       "9            None   Q640       Harald Krichel   \n",
       "\n",
       "                                candidacy  type                    religion  \n",
       "0                      [Q698073, Q697949]  item                   [Q682443]  \n",
       "1                                    None  item                        None  \n",
       "2                                    None  item                        None  \n",
       "3  [Q327959, Q464075, Q3586276, Q4450587]  item  [Q329646, Q682443, Q33203]  \n",
       "4                                    None  item                        None  \n",
       "5                                    None  item                     [Q1841]  \n",
       "6                                    None  item                     [Q1841]  \n",
       "7                                    None  item                     [Q1841]  \n",
       "8                                    None  item                        None  \n",
       "9                                    None  item                        None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speaker_attributes = pd.read_parquet('data/speaker_attributes.parquet')\n",
    "df_speaker_attributes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25498c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14576"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupations = df_speaker_attributes['occupation'].explode('occupation').drop_duplicates()\n",
    "occupations.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff2ec1",
   "metadata": {},
   "source": [
    "Finally we notice that there are more than 14'500 occupations, we will have to see when we can have their label, if we can group them together to facilitate our analysis. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cffb4dc13a2c8d65c4e22bea49294395e13ba2eea796238c356a7a0a6291307b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
